theme(axis.text.x = element_text(angle = 90,
vjust = 1,
size = 12,
hjust = 1)) +
coord_fixed()
# alternative for simpler plotting
library(corrplot)
corrplot(cor_matrix)
# plot the histograms
ggplot(df_long, aes(x = value, fill = variable)) +
geom_histogram(bins = 30,
alpha = 0.6,
position = 'identity') +
facet_wrap(~ variable,
scales = 'free') +
theme_minimal() +
labs(title = "Histograms of Intensity Variables",
x = "Value",
y = "Frequency",
fill = "Variable") +
theme(plot.title = element_text(hjust = 0.5))
# VISUAL INSPECTION
# plot the all spectral lines
ggplot(df_long, aes(x = wavenumber, y = value, color = variable)) +
geom_line() +
theme_minimal() +
labs(title = "Multiple Intensity Variables Against Wavelength",
x = "Wavelength",
y = "Intensity",
color = "Variable") +
theme(plot.title = element_text(hjust = 0.5))
# PREPARE DATA FOR COVARIANCE AND CORRELATION
library(dplyr)
selected_data = df %>% select(starts_with("c"))
View(selected_data)
#COVARIANCE
cov_matrix = cov(selected_data)
print(cov_matrix)
# prepare matrix to be ploted as heatmap
melted_cov = melt(cov_matrix)
melted_cov$Var1 <- as.factor(melted_cov$Var1)
melted_cov$Var2 <- as.factor(melted_cov$Var2)
melted_cov$value <- as.numeric(melted_cov$value)
#plot the heatmap
ggplot(melted_cov, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = median(melted_cov$value), limit = c(min(melted_cov$value), max(melted_cov$value)), space = "Lab",
name = "Covariance") +
theme_minimal() +
labs(title = "Covariance Matrix Heatmap",
x = "Variables",
y = "Variables") +
theme(axis.text.x = element_text(angle = 0, vjust = 1,
size = 12, hjust = 1),
plot.title = element_text(hjust = 0.5))
# CORRELATION
# make correlation matrix
cor_matrix = cor(selected_data)
print(cor_matrix)
# t-test for the matrix
library(Hmisc)
rcorr(as.matrix(selected_data))
# make data suitable for graphs
library(reshape2)
melted_cor = melt(cor_matrix)
# plot the correlation matrix
library(ggplot2)
ggplot(data = melted_cor, aes(x = Var1, y= Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue",
high = "red",
mid = "white",
midpoint = median(melted_cor$value),
limit = c(min(melted_cor$value), max(melted_cor$value)),
space="Lab",
name="Pearson correlation\n of FTIR spectra") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90,
vjust = 1,
size = 12,
hjust = 1)) +
coord_fixed()
# read and inspect dataframe
df = read.csv('central_points_good.csv')
View(df)
# CHECK THE NORMALITY
# vizualize distribution to check normality
#reshape the dataframe and check it
library(tidyr)
df_long = pivot_longer(df, cols = starts_with("c"),
names_to = "variable",
values_to = "value")
# plot the histograms
ggplot(df_long, aes(x = value, fill = variable)) +
geom_histogram(bins = 30,
alpha = 0.6,
position = 'identity') +
facet_wrap(~ variable,
scales = 'free') +
theme_minimal() +
labs(title = "Histograms of Intensity Variables",
x = "Value",
y = "Frequency",
fill = "Variable") +
theme(plot.title = element_text(hjust = 0.5))
# VISUAL INSPECTION
# plot the all spectral lines
ggplot(df_long, aes(x = wavenumber, y = value, color = variable)) +
geom_line() +
theme_minimal() +
labs(title = "Multiple Intensity Variables Against Wavelength",
x = "Wavelength",
y = "Intensity",
color = "Variable") +
theme(plot.title = element_text(hjust = 0.5))
# PREPARE DATA FOR COVARIANCE AND CORRELATION
library(dplyr)
selected_data = df %>% select(starts_with("c"))
#COVARIANCE
cov_matrix = cov(selected_data)
print(cov_matrix)
# prepare matrix to be ploted as heatmap
melted_cov = melt(cov_matrix)
melted_cov$Var1 <- as.factor(melted_cov$Var1)
melted_cov$Var2 <- as.factor(melted_cov$Var2)
melted_cov$value <- as.numeric(melted_cov$value)
#plot the heatmap
ggplot(melted_cov, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = median(melted_cov$value), limit = c(min(melted_cov$value), max(melted_cov$value)), space = "Lab",
name = "Covariance") +
theme_minimal() +
labs(title = "Covariance Matrix Heatmap",
x = "Variables",
y = "Variables") +
theme(axis.text.x = element_text(angle = 0, vjust = 1,
size = 12, hjust = 1),
plot.title = element_text(hjust = 0.5))
# CORRELATION
# make correlation matrix
cor_matrix = cor(selected_data)
print(cor_matrix)
# t-test for the matrix
library(Hmisc)
rcorr(as.matrix(selected_data))
# make data suitable for graphs
library(reshape2)
melted_cor = melt(cor_matrix)
# plot the correlation matrix
library(ggplot2)
# plot the correlation matrix
library(ggplot2)
ggplot(data = melted_cor, aes(x = Var1, y= Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue",
high = "red",
mid = "white",
midpoint = median(melted_cor$value),
limit = c(min(melted_cor$value), max(melted_cor$value)),
space="Lab",
name="Pearson correlation\n of FTIR spectra") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90,
vjust = 1,
size = 12,
hjust = 1)) +
coord_fixed()
ggplot(data = melted_cov, aes(x = Var1, y= Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue",
high = "red",
mid = "white",
midpoint = median(melted_cov$value),
limit = c(min(melted_cov$value), max(melted_cor$value)),
space="Lab",
name="Covariance\n of FTIR spectra") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90,
vjust = 1,
size = 12,
hjust = 1)) +
coord_fixed()
ggplot(data = melted_cov, aes(x = Var1, y= Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue",
high = "red",
mid = "white",
midpoint = median(melted_cov$value),
limit = c(min(melted_cov$value), max(melted_cov$value)),
space="Lab",
name="Covariance\n of FTIR spectra") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 90,
vjust = 1,
size = 12,
hjust = 1)) +
coord_fixed()
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
# CHECK THE NORMALITY
# vizualize distribution to check normality
#reshape the dataframe and check it
library(tidyr)
df_long = pivot_longer(df, cols = starts_with("c"),
names_to = "variable",
values_to = "value")
# plot the histograms
ggplot(df_long, aes(x = value, fill = variable)) +
geom_histogram(bins = 30,
alpha = 0.6,
position = 'identity') +
facet_wrap(~ variable,
scales = 'free') +
theme_minimal() +
labs(title = "Histograms of Intensity Variables",
x = "Value",
y = "Frequency",
fill = "Variable") +
theme(plot.title = element_text(hjust = 0.5))
install.packages("MASS")
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
View(df)
# transpose dataframe and inspect
df_pca = t(df)
View(df_pca)
# read and inspect dataframe
df = read.csv('central_points_good.csv')
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# inspect the results
View(df_pca)
# CALCULATE PCs
results = prcomp(df_pca, scale=TRUE)
# CALCULATE PCs
results = prcomp(df_pca, scale=FALSE)
# reverse eigenvectors
results$rotation = -1*results$rotation
# dispay PCs
results$rotation
# delete rows with 0
df_pca_clean = subset(df_pca, !(b %in% c(0)))
# delete rows with 0
df_pca = df_pca[apply(df_pca, 1, function(row) all(row != 0)), ]
View(df_pca)
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# inspect the results
View(df_pca)
# delete rows with 0
df_pca = df_pca[apply(df_pca !=0, all), ]
# delete rows with 0
df_pca = df_pca[apply(df_pca !=0, 1, all), ]
View(df_pca)
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
View(df)
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# inspect the results
View(df_pca)
# delete rows with 0
df_pca = df_pca[rowSums(df_pca == 0, na.rm = TRUE) == 0, ]
View(df_pca)
# delete rows with 0
df_pca = df_pca[columnSums(df_pca == 0, na.rm = TRUE) == 0, ]
# delete rows with 0
df_pca = df_pca[colSums(df_pca == 0, na.rm = TRUE) == 0, ]
# delete rows with 0
df_pca_sub = apply(df_pca, 1, function(row) all(row !=0 ))
df_pca = df_pca[row_sub, ]
# delete rows with 0
df_pca_sub = apply(df_pca, 1, function(row) all(row !=0 ))
df_pca = df_pca[df_pca_sub, ]
View(df_pca)
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# delete rows with 0
df_pca_sub = apply(df_pca, 1, function(row) all(row !=0 ))
df_pca = df_pca[df_pca_sub, ]
View(df_pca)
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# delete rows with 0
df_pca[df_pca == 0] <- NA
# Remove columns that contain only NA (previously zeros)
df_pca = df_pca[, colSums(is.na(df)) != nrow(df)]
View(df_pca)
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# delete rows with 0
df_pca[df_pca == 0] <- NA
# Remove columns that contain only NA (previously zeros)
df_pca = df_pca[, colSums(is.na(df_pca)) != nrow(df_pca)]
View(df_pca)
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# inspect the results
View(df_pca)
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
View(df)
df_filtered <- df %>%
filter_all(any_vars(. != 0))
View(df_filered)
View(df_filtered)
library(dplyr)
df_filtered <- df %>%
filter_all(any_vars(. != 0))
View(df_filtered)
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
library(dplyr)
df = df[apply(df!=0, 1, all),]
View(df)
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# inspect the results
View(df_pca)
# CALCULATE PCs
results = prcomp(df_pca, scale=TRUE)
# reverse eigenvectors
results$rotation = -1*results$rotation
# dispay PCs
results$rotation
biplot(results, scale = 0)
#calculate total variance explained by each principal component
results$sdev^2 / sum(results$sdev^2)
#create scree plot
qplot(c(1:4), var_explained) +
geom_line() +
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
#calculate total variance explained by each principal component
var_explained = results$sdev^2 / sum(results$sdev^2)
#create scree plot
qplot(c(1:4), var_explained) +
geom_line() +
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
#create scree plot
qplot(c(1:6), var_explained) +
geom_line() +
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
library(ggplot2)
# Convert scores to a data frame
scores_df <- as.data.frame(results$x)
# Assuming you want to plot the first two principal components (PC1 and PC2)
ggplot(scores_df, aes(x = PC1, y = PC2)) +
geom_point() +
labs(x = "PC1", y = "PC2", title = "PCA Score Plot")
# set work directory
setwd("C:/Users/Lenovo/Documents/Programiranje/PhD/SpectralTool/datasets")
# read and inspect dataframe
df = read.csv('central_points_good.csv')
# remove rows with 0, else scaling wont work
library(dplyr)
df = df[apply(df!=0, 1, all),]
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# CALCULATE PCs
results = prcomp(df_pca, scale=TRUE)
# reverse eigenvectors
results$rotation = -1*results$rotation
# biplot (useless in this case)
biplot(results, scale = 0)
#calculate total variance explained by each principal component
var_explained = results$sdev^2 / sum(results$sdev^2)
#create scree plot
qplot(c(1:6), var_explained) +
geom_line() +
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
# Convert scores to a data frame
scores_df <- as.data.frame(results$x)
# Assuming you want to plot the first two principal components (PC1 and PC2)
ggplot(scores_df, aes(x = PC1, y = PC2)) +
geom_point() +
labs(x = "PC1", y = "PC2", title = "PCA Score Plot")
# read and inspect dataframe
df = read.csv('central_points_bad.csv')
View(df)
# remove rows with 0, else scaling wont work
library(dplyr)
df = df[apply(df!=0, 1, all),]
# TRANSPOSE DATAFRAME, TIDY UP AND INSPECT
# tranpose
df_pca = t(df)
# make first row column names
colnames(df_pca) = as.character(unlist(df_pca[1, ]))
# replace previous column names and reset
df_pca = df_pca[-1, ]
rownames(df) = NULL
# CALCULATE PCs
results = prcomp(df_pca, scale=TRUE)
# reverse eigenvectors
results$rotation = -1*results$rotation
# dispay PCs
results$rotation
# biplot (useless in this case)
biplot(results, scale = 0)
#calculate total variance explained by each principal component
var_explained = results$sdev^2 / sum(results$sdev^2)
#create scree plot
qplot(c(1:6), var_explained) +
geom_line() +
xlab("Principal Component") +
ylab("Variance Explained") +
ggtitle("Scree Plot") +
ylim(0, 1)
library(ggplot2)
# Convert scores to a data frame
scores_df <- as.data.frame(results$x)
# Assuming you want to plot the first two principal components (PC1 and PC2)
ggplot(scores_df, aes(x = PC1, y = PC2)) +
geom_point() +
labs(x = "PC1", y = "PC2", title = "PCA Score Plot")
